{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array([\n",
    "        'Pada matahari yang bersinar',\n",
    "        'Pada cuaca yang dingin',\n",
    "        'Pada matahari yang bersinar, pada cuaca yang dingin, dan satu dan satu yang dua'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pada': 6, 'matahari': 5, 'yang': 8, 'bersinar': 0, 'cuaca': 1, 'dingin': 3, 'dan': 2, 'satu': 7, 'dua': 4}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bersinar', 'cuaca', 'dan', 'dingin', 'dua', 'matahari', 'pada', 'satu', 'yang']\n"
     ]
    }
   ],
   "source": [
    "print(count.get_feature_names())\n",
    "a=count.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 1 1 0 1]\n",
      " [0 1 0 1 0 0 1 0 1]\n",
      " [1 1 2 1 1 1 2 2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "print(bag.toarray())\n",
    "b=bag.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bersinar</th>\n",
       "      <th>cuaca</th>\n",
       "      <th>dan</th>\n",
       "      <th>dingin</th>\n",
       "      <th>dua</th>\n",
       "      <th>matahari</th>\n",
       "      <th>pada</th>\n",
       "      <th>satu</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bersinar cuaca dan dingin dua matahari pada satu yang\n",
       "doc1        1     0   0      0   0        1    1    0    1\n",
       "doc2        0     1   0      1   0        0    1    0    1\n",
       "doc3        1     1   2      1   1        1    2    2    3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfa =pd.DataFrame(data=a)\n",
    "dfb =pd.DataFrame(data=b,index=[\"doc1\", \"doc2\",\"doc3\"],columns=[a])\n",
    "dfb\n",
    "#count_row = dfb.shape[0]\n",
    "\n",
    "#count_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kata yang paling besar kata (pada) /term frequency dalam dokumen ketiga,paling sering muncul kata tersebut, tetapi setelah ditransformasi kedalam  tf-idfs, kata tersebut relatif kecil nilai tf-idfnya. Perhatikan kemunculan kata tersebut di  (discriminatory information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{idf} (t,d) = log\\frac{1 + n_d}{1 + \\text{df}(d, t)}$$\n",
    "\n",
    "Persamaan tf-idf yang diimplementasikan dalam scikit-learn adalah:\n",
    "\n",
    "$$\\text{tf-idf}(t,d) = \\text{tf}(t,d) \\times (\\text{idf}(t,d)+1)$$\n",
    "\n",
    "kemudian umumnya dinormalisasi term frequenciy sebelum dihitung tf-idfs, ( `TfidfTransformer` menormalisasi secara langsung)\n",
    "\n",
    "Menggunakan berikut (default untuk scikit learn)\n",
    "\n",
    "$$v_{\\text{norm}} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v_{1}^{2} + v_{2}^{2} + \\dots + v_{n}^{2}}} = \\frac{v}{\\big (\\sum_{i=1}^{n} v_{i}^{2}\\big)^\\frac{1}{2}}$$\n",
    "\n",
    "Silahkan hitung tf-idf untuk kata `yang` dokumen ke 3\n",
    "\n",
    "Banyak dokumen ($n_d=3$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55847784 0.         0.         0.         0.         0.55847784\n",
      "  0.43370786 0.         0.43370786]\n",
      " [0.         0.55847784 0.         0.55847784 0.         0.\n",
      "  0.43370786 0.         0.43370786]\n",
      " [0.19103892 0.19103892 0.50238645 0.19103892 0.25119322 0.19103892\n",
      "  0.29671753 0.50238645 0.44507629]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, \n",
    "                         norm='l2', \n",
    "                         smooth_idf=True)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs))\n",
    "      .toarray())\n",
    "tf=tfidf.fit_transform(count.fit_transform(docs)).toarray()\n",
    "\n",
    "dfbtf =pd.DataFrame(data=tf,index=[\"doc1\", \"doc2\",\"doc3\"],columns=[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf kata \"yang\" 0.44507629390649395\n"
     ]
    }
   ],
   "source": [
    "a=tfidf.fit_transform(count.fit_transform(docs)).toarray()\n",
    "a.shape\n",
    "print('tf_idf kata \"yang\"',a[(2,8)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saya sangat senang sekali kalau ibukota pindah...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tidak terlalu nikmat kalau dikalimantan, sanga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>susah transportasi kalau pergi  kalimantan.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya sangat mendukung kalau pindah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berat ongkos kalau pindah kalimantan.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  saya sangat senang sekali kalau ibukota pindah...          1\n",
       "1  tidak terlalu nikmat kalau dikalimantan, sanga...          0\n",
       "2        susah transportasi kalau pergi  kalimantan.          0\n",
       "3                 saya sangat mendukung kalau pindah          1\n",
       "4              berat ongkos kalau pindah kalimantan.          0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('preproses.csv', encoding='utf-8')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bersinar', 'cuaca', 'dan', 'dingin', 'dua', 'matahari', 'pada', 'satu', 'yang']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(docs)\n",
    "print(count.get_feature_names())\n",
    "a=count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def praproses(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)()(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nova arianto timnas seperti dibuat main main padahal mereka dibiayai uang rakyat'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "praproses(df.loc[3, 'tweet'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us print the contents of the vocabulary to get a better understanding of the underlying concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55847784 0.         0.         0.         0.         0.55847784\n",
      "  0.43370786 0.         0.43370786]\n",
      " [0.         0.55847784 0.         0.55847784 0.         0.\n",
      "  0.43370786 0.         0.43370786]\n",
      " [0.19103892 0.19103892 0.50238645 0.19103892 0.25119322 0.19103892\n",
      "  0.29671753 0.50238645 0.44507629]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, \n",
    "                         norm='l2', \n",
    "                         smooth_idf=True)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.fit_transform(count.fit_transform(df.head())).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, \n",
    "                         norm='l2', \n",
    "                         smooth_idf=True)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs))\n",
    "      .toarray())\n",
    "tf=tfidf.fit_transform(count.fit_transform(docs)).toarray()\n",
    "\n",
    "dfbtf =pd.DataFrame(data=tf,index=[\"doc1\", \"doc2\",\"doc3\"],columns=[a])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
